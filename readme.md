# ğŸ§  AI Assistant MCP (Master Control Platform)

A modular AI assistant system inspired by Claude Desktop and Cursor, designed to route tasks to local agents/tools using local LLMs (via Ollama) or future cloud backends.

## ğŸ“Œ Project Overview

This assistant is built around a modular architecture where:

- The Controller (core logic) routes user input to various agents.
- Agents handle specific domains like code generation or diagnostics.
- Tools are utilities agents can use (file access, shell commands, system specs, webhooks).
- A local or remote LLM handles reasoning and generation (via wrappers).
- The CLI interface lets you interact with the system easily.

## ğŸ§± File Structure (as of now)

ai_assistant_mcp/
â”œâ”€â”€ main.py                    # ğŸ”¹ Entry point of the app
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ mcp_config.json        # ğŸŒ Claude-style config for agents/tools
â”‚
â”œâ”€â”€ core/                      # ğŸ§  Core system logic
â”‚   â”œâ”€â”€ controller.py          # Routes input â†’ agents/tools
â”‚   â”œâ”€â”€ registry.py            # Registers and stores modules
â”‚   â””â”€â”€ mcp_loader.py          # Loads and parses config
â”‚
â”œâ”€â”€ llm/                       # ğŸ§  LLM Wrappers (local/cloud)
â”‚   â”œâ”€â”€ base.py                # LLM interface
â”‚   â”œâ”€â”€ ollama_wrapper.py      # Wrapper for local models (via Ollama)
â”‚   â””â”€â”€ openai_wrapper.py      # (optional) API-based fallback
â”‚
â”œâ”€â”€ agents/                    # ğŸ¤– Modular AI agents
â”‚   â”œâ”€â”€ base.py                # Agent interface
â”‚   â”œâ”€â”€ code_agent.py          # Generates code from user input
â”‚   â””â”€â”€ diagnostics_agent.py   # Uses SpecsTool & CommandTool to analyze system
â”‚
â”œâ”€â”€ tools/                     # ğŸ› ï¸ Plug-in utilities
â”‚   â”œâ”€â”€ base.py                # Tool interface
â”‚   â”œâ”€â”€ file_tool.py           # Read/write files (structured via kwargs)
â”‚   â”œâ”€â”€ command_tool.py        # Run shell commands (supports raw_input)
â”‚   â”œâ”€â”€ specs_tool.py          # Get CPU/RAM/disk info
â”‚   â””â”€â”€ n8n_tool.py            # Trigger n8n automation
â”‚
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ cli.py                 # ğŸ’¬ CLI interaction layer
â”‚
â””â”€â”€ utils/                     # âš™ï¸ General helpers
    â”œâ”€â”€ helpers.py             # `parse_kwargs()` to extract key=value args
    â””â”€â”€ logger.py              # Logging utilities (TBD)

## ğŸš€ Setup Instructions

### 1. Clone the repo and navigate into it:

```bash
git clone <repo-url>
cd ai_assistant_mcp
```

### 2. Set up a virtual environment (optional but recommended):

```bash
python -m venv venv
.env\Scriptsctivate  # Windows
```

### 3. Install dependencies:

There are no dependencies yet. Future ones will be added to requirements.txt.

### 4. Install and run Ollama:

Download from https://ollama.com

```bash
ollama run deepseek-coder
```

### 5. Run the CLI interface:

```bash
python main.py
```

Then try commands like:

```bash
run code create a react app
run diagnostics check disk
use tool file action=write path=test.txt content="hello world"
use tool file action=read path=test.txt
use tool command raw_input="echo Hello from terminal"
```

## âš™ï¸ How It Works

### main.py

- Loads the MCP config and starts the controller loop.

### config/mcp_config.json

- Defines external modules (e.g. n8n, file access paths) in Claude-compatible format.

### core/controller.py

- Central brain of the project. It:
  - Loads all agents/tools from their classes
  - Listens for user input
  - Parses commands like `run` or `use tool`
  - Uses `parse_kwargs()` to convert CLI args into structured kwargs

### utils/helpers.py

- `parse_kwargs()` converts `key=value` strings into `**kwargs` dicts.

### agents/*_agent.py

- Each agent handles one responsibility (code, diagnostics, etc.)
- Can call tools under the hood for extended capabilities

### tools/*_tool.py

- Tools do low-level work like reading files, calling commands, or hitting APIs.

## ğŸ“ Next Milestones

- âœ… Add key=value parsing and CLI fallback system
- ğŸ”„ Add fallback to raw_input when no key=value args are given
- ğŸ§ª Wire `DiagnosticsAgent` to call SpecsTool and CommandTool with structured args
- ğŸ”§ Connect CodeAgent to local LLM via Ollama
- ğŸ§° Add `--debug` and CLI flags to cli.py
- ğŸ§  Optional: add a HelpAgent that suggests actions

## ğŸ’¡ Long-Term Vision

- Frontend GUI using Flask or Tauri
- Memory/plan management agent
- Multi-agent task delegation
- Cloud fallback to OpenAI or GitHub Models
- VSCode extension integration
- Vector DB integration (RAG)